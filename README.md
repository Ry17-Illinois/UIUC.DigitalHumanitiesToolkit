# CODEBOOKS - Digital Humanities Metadata Pipeline

A comprehensive Python application for extracting and managing metadata from archival documents using multiple OCR engines and AI-powered analysis.

## âœ¨ Features

### ðŸ” **Multi-Engine OCR Processing**
- **EasyOCR**: GPU-accelerated AI-powered text extraction
- **Tesseract**: Traditional OCR with advanced preprocessing
- **PyPDF2**: Direct PDF text extraction
- **OpenAI OCR**: GPT-4o vision-based transcription
- **Ollama OCR**: Local LLM image transcription (privacy-focused)

### ðŸ¤– **Dual AI Metadata Generation**
- **OpenAI GPT**: Cloud-based metadata extraction using GPT-4o-mini
- **Ollama Local**: Privacy-focused local LLM processing
- **Smart Prompting**: Optimized prompts for clean metadata extraction
- **Interactive Approval**: Review and approve AI-generated suggestions

### ðŸ“Š **Advanced Analysis & Evaluation**
- **OCR Quality Assessment**: Compare engine performance with standard metrics
- **Ground Truth Comparison**: Evaluate accuracy using reference text
- **Visual Analytics**: Charts and graphs for performance analysis
- **Cross-Engine Evaluation**: Comprehensive quality scoring

### ðŸŽ¨ **Modern Interface**
- **Streamlined Workflow**: Intuitive step-by-step process
- **Resizable Panels**: Customizable workspace layout
- **Tabbed Interface**: Separate processing and analysis views
- **Progress Indicators**: Real-time feedback on operations
- **Keyboard Shortcuts**: Power user efficiency (Ctrl+O, Ctrl+R, F5)

## ðŸš€ Installation

### 1. Python Dependencies
```bash
pip install -r requirements.txt
```

### 2. OCR Engines Setup

**Tesseract OCR:**
- Windows: Download from https://github.com/UB-Mannheim/tesseract/wiki
- macOS: `brew install tesseract`
- Linux: `sudo apt-get install tesseract-ocr`

**Ollama (Optional - for local AI):**
```bash
# Install Ollama from https://ollama.ai
# Then pull a vision model:
ollama pull gemma3
```

### 3. API Keys (Optional)
- **OpenAI**: Get API key from https://platform.openai.com/api-keys
- Configure through the application's "Configure AI" button

## ðŸ“– Usage

### Quick Start
```bash
python main.py
```

### Workflow
1. **ðŸ“ Add Files**: Import individual files or entire directories
2. **ðŸ” OCR Processing**: Choose engine (EasyOCR, Tesseract, PyPDF2, OpenAI, Ollama) and run
3. **ðŸ¤– AI Setup**: Configure OpenAI API or launch Ollama for local processing
4. **ðŸ“ Generate Metadata**: Select AI model and extract Dublin Core metadata
5. **ðŸ› ï¸ Analyze**: Evaluate OCR quality and compare engine performance

### Keyboard Shortcuts
- `Ctrl+O`: Add files
- `Ctrl+R`: Run selected OCR engine
- `F5`: Refresh display

## File Structure

```
CODEBOOKS/
â”œâ”€â”€ main.py                  # Modern GUI application
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ledger_manager.py    # CSV-based metadata management
â”‚   â”œâ”€â”€ ocr_processor.py     # Multi-engine OCR processing
â”‚   â”œâ”€â”€ prompt_processor.py  # Dual AI metadata extraction
â”‚   â””â”€â”€ ocr_evaluator.py     # Quality assessment & analytics
â”œâ”€â”€ prompts/                 # Dublin Core prompt templates
â”‚   â”œâ”€â”€ title.txt           # Title extraction prompts
â”‚   â”œâ”€â”€ creator.txt         # Creator/author prompts
â”‚   â”œâ”€â”€ subject.txt         # Subject classification
â”‚   â”œâ”€â”€ description.txt     # Content description
â”‚   â”œâ”€â”€ date.txt           # Date extraction
â”‚   â””â”€â”€ type.txt           # Document type classification
â”œâ”€â”€ metadata_ledger.csv     # Generated metadata database
â””â”€â”€ requirements.txt        # Python dependencies

## ðŸ¤ Contributing

Contributions welcome! Areas for development:
- Additional OCR engines
- New AI model integrations  
- Enhanced evaluation metrics
- UI/UX improvements
- Documentation and tutorials

## ðŸ“„ License

Open source - see LICENSE file for details.
```

## ðŸ“‹ Dublin Core Metadata Fields

**Currently Supported:**
- **Title**: Document titles and headings
- **Creator**: Authors, organizations, publishers
- **Subject**: Topics, keywords, classifications
- **Description**: Content summaries and abstracts
- **Date**: Creation, publication, or modification dates
- **Type**: Document format and genre classification

**Extensible**: Add new fields by creating prompt files in `prompts/` directory

## ðŸ”§ Extending the System

### Adding New OCR Engines
```python
class CustomOCRModel(BaseOCRModel):
    def process_image(self, image: Image.Image) -> str:
        # Your OCR implementation
        return extracted_text
    
    @property
    def name(self) -> str:
        return "custom_ocr"

# Add to processor
ocr_processor.add_model("custom", CustomOCRModel())
```

### Adding Dublin Core Fields
1. Create `prompts/new_field.txt` with extraction instructions
2. Field automatically appears in metadata generation interface
3. Results stored in ledger with status tracking

### Custom AI Models
- Extend `PromptProcessor` for new AI providers
- Implement `_generate_custom()` method
- Add to model selection dropdown

## ðŸ’¾ Data Management

### Ledger System
- **CSV Storage**: All metadata in `metadata_ledger.csv`
- **Unique IDs**: Each file tracked with UUID
- **Status Tracking**: Monitor processing state for all engines
- **Batch Operations**: Process multiple files simultaneously
- **Error Recovery**: Clear and retry failed operations
- **Data Safety**: Confirmation required for deletions

### OCR Results Storage
- **Multi-Engine Support**: Separate columns for each OCR engine
- **Text Preservation**: Full OCR output stored and displayable
- **Quality Metrics**: Performance scores and comparisons
- **Export Ready**: CSV format for analysis in other tools

## ðŸ“‹ Requirements

### System Requirements
- **Python**: 3.8+ (3.10+ recommended)
- **Memory**: 4GB RAM minimum (8GB+ for GPU acceleration)
- **Storage**: 1GB free space for models and data

### Optional Components
- **OpenAI API Key**: For cloud-based AI metadata generation
- **CUDA GPU**: For EasyOCR acceleration (optional)
- **Ollama**: For local AI processing (privacy-focused)

### Supported File Formats
- **Images**: JPG, JPEG, PNG, TIF, TIFF
- **Documents**: PDF (both text and image-based)
- **Batch Processing**: Entire directories with mixed formats

## ðŸŽ¯ Use Cases

- **Digital Archives**: Batch metadata extraction for historical documents
- **Library Sciences**: Cataloging and classification workflows
- **Research Projects**: OCR quality assessment and comparison
- **Document Digitization**: Automated metadata generation pipelines
- **Privacy-Sensitive Work**: Local processing with Ollama integration